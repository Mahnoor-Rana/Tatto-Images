{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this(by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the input data","metadata":{}},{"cell_type":"code","source":"images_path = '/kaggle/input/tattoo-test-images'\nlabels_path = '/kaggle/input/resized-tattoo-labels'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_lst = os.listdir(images_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bb = pd.read_csv('/kaggle/input/resized-tattoo-labels/resized_IMG_0998.txt', columns=['classs', 'xmin', 'xmax', 'ymin', 'ymax'])\nbb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_bbox = pd.read-csv(img_label)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Before you start\n\nLet's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.","metadata":{"id":"L2s3TnW4nhjC"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"Frcrk09FhJeV","outputId":"d7f28782-6576-4c9c-bd08-c105e5e4c553","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant. ","metadata":{"id":"Iov3yhoRnxG2"}},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(\"HOME:\", HOME)","metadata":{"id":"dgS8jFPMnj5h","outputId":"d28cb003-6e7d-4234-ecb5-9b0cdd15bc95","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install Segment Anything Model (SAM) and other dependencies","metadata":{"id":"YN3DPGZSn57p"}},{"cell_type":"code","source":"%cd {HOME}\n\nimport sys\n!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'","metadata":{"id":"1H9YruJen0Q8","outputId":"b12336e9-4bbc-4c00-bbc7-36ce68d7e0cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision","metadata":{"id":"G3CtzYroC2Lb","outputId":"44413799-0473-4db8-a4e8-6e21900c31d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download SAM weights","metadata":{"id":"2VeYIWh1iDWW"}},{"cell_type":"code","source":"%cd {HOME}\n!mkdir {HOME}/weights\n%cd {HOME}/weights\n\n!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth","metadata":{"id":"Aszw1OxBwowI","outputId":"22c30f78-69bf-4e43-8c46-2e066c0bd8f6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nCHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\nprint(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))","metadata":{"id":"sxoFmhsHw_fG","outputId":"82f46abd-d058-4920-adfd-03bccbada72f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-process dataset\n\n**NONE:** Let's download few example images. Feel free to use your images or videos.","metadata":{"id":"aIlYzcqqpZdc"}},{"cell_type":"code","source":"dataset = '/kaggle/input/tattoo-test-dataset'\n\nimgs = os.listdir(dataset)\nimgs","metadata":{"id":"PKv4fEE1pdKE","outputId":"60202f07-fdff-4764-b5ee-5cf1bf0bc834","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{"id":"vlhbd_f4xfiJ"}},{"cell_type":"code","source":"import torch\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\n\n\ndef load_SAM_predictor():\n\n    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    MODEL_TYPE = \"vit_h\"\n\n    sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n    \n    mask_predictor = SamPredictor(sam)\n    \n    return mask_predictor","metadata":{"id":"t6_9PSZupghA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`SamAutomaticMaskGenerator` returns a `list` of masks, where each mask is a `dict` containing various information about the mask:\n\n* `segmentation` - `[np.ndarray]` - the mask with `(W, H)` shape, and `bool` type\n* `area` - `[int]` - the area of the mask in pixels\n* `bbox` - `[List[int]]` - the boundary box of the mask in `xywh` format\n* `predicted_iou` - `[float]` - the model's own prediction for the quality of the mask\n* `point_coords` - `[List[List[float]]]` - the sampled input point that generated this mask\n* `stability_score` - `[float]` - an additional measure of mask quality\n* `crop_box` - `List[int]` - the crop of the image used to generate this mask in `xywh` format","metadata":{"id":"fxO265XOymA2"}},{"cell_type":"markdown","source":"## Generate Segmentation with Bounding Box\n\nThe `SamPredictor` class provides an easy interface to the model for prompting the model. It allows the user to first set an image using the `set_image` method, which calculates the necessary image embeddings. Then, prompts can be provided via the `predict` method to efficiently predict masks from those prompts. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction.","metadata":{"id":"NXKPiidy9nwH"}},{"cell_type":"code","source":"# # helper function that loads an image before adding it to the widget\n\n# import base64\n\n# def encode_image(filepath):\n#     with open(filepath, 'rb') as f:\n#         image_bytes = f.read()\n#     encoded = str(base64.b64encode(image_bytes), 'utf-8')\n#     return \"data:image/jpg;base64,\"+encoded","metadata":{"id":"WSwoXkDi9uVD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** Execute cell below and use your mouse to draw bounding box on the image 👇","metadata":{"id":"xFGBhRQNC0-H"}},{"cell_type":"code","source":"# IS_COLAB = False\n\n# if IS_COLAB:\n#     from google.colab import output\n#     output.enable_custom_widget_manager()\n\n# from jupyter_bbox_widget import BBoxWidget\n\n# widget = BBoxWidget()\n# widget.image = encode_image(IMAGE_PATH)\n# widget","metadata":{"id":"Zieb7wDZCoj2","outputId":"927f71b1-6f70-4cc4-fde3-7d70b1213c81","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# widget.bboxes","metadata":{"id":"sSAhAXOULj0t","outputId":"790db76b-b40b-4470-f4e2-2eac941a15e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate masks with SAM","metadata":{"id":"Wsy-GikiuX5l"}},{"cell_type":"markdown","source":"**NOTE:** `SamPredictor.predict` method takes `np.ndarray` `box` argument in `[x_min, y_min, x_max, y_max]` format. Let's reorganise your data first","metadata":{"id":"Rqxt0CdkFUf8"}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef yolo_to_coco(center_x, center_y, bbox_width, bbox_height, width, height):\n    x_min = int((center_x - bbox_width/2) * width)\n    y_min = int((center_y - bbox_height/2) * height)\n    coco_width = int(bbox_width * width)\n    coco_height = int(bbox_height * height)\n    \n    return x_min, y_min, coco_width, coco_height\n\n\ndef get_bbox(a, b, aa, bb, image_width, image_height):\n    \n    x,y, xx, yy =  yolo_to_coco(a, b, aa, bb, image_width, image_height)\n    \n    # default_box is going to be used if you will not draw any box on image above\n    default_box = {'x': x, 'y': y, 'width': xx, 'height': yy, 'label': ''}\n\n    # box = widget.bboxes[0] if widget.bboxes else default_box\n    box = default_box\n    box = np.array([\n        box['x'], \n        box['y'], \n        box['x'] + box['width'], \n        box['y'] + box['height']\n    ])\n    return box","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef predict_mask(IMAGE_PATH, mask_predictor, box):\n\n\n    image_bgr = cv2.imread(IMAGE_PATH)\n#     image_bgr = cv2.resize(image_bgr, (416, 416))\n    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n\n    mask_predictor.set_image(image_rgb)\n\n    masks, scores, logits = mask_predictor.predict(\n        box=box,\n        multimask_output=True\n    )\n    return masks, scores, logits","metadata":{"id":"NGxKHiK2uqtE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Results visualisation with Supervision","metadata":{"id":"kV_JOjHBNnV5"}},{"cell_type":"code","source":"def visualize_predicted_masks(mask_par, box, IMAGE_PATH):\n\n    image_bgr = cv2.imread(IMAGE_PATH)\n#     image_bgr = cv2.resize(image_bgr, (416, 416))\n    \n    box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n    mask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n\n    detections = sv.Detections(\n        xyxy=sv.mask_to_xyxy(masks=masks),\n        mask=masks\n    )\n    detections = detections[detections.area == np.max(detections.area)]\n\n    source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections, skip_label=True)\n    segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n\n    sv.plot_images_grid(\n        images=[source_image, segmented_image],\n        grid_size=(1, 2),\n        titles=['source image', 'segmented image']\n    )\n    return segmented_image","metadata":{"id":"U2opSwP1Np7s","outputId":"9b7a23d6-b9e5-4e5f-96b4-6ff7ab420c3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import supervision as v\n\n# sv.plot_images_grid(\n#     images=masks,\n#     grid_size=(1, 4),\n#     size=(16, 4)\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Background","metadata":{}},{"cell_type":"code","source":"import cv2\n\ndef extract_tattoo(IMAGE_PATH, segmented_image, mask_value):\n\n    original_image = cv2.imread(IMAGE_PATH)\n#     original_image = cv2.resize(original_image, (416, 416))\n\n    segmented_image = segmented_image\n\n    # Load the mask value for the segmented image\n    mask_value = mask_value\n\n    # Create a new image of the same size as the original image\n    extracted_image = np.zeros_like(original_image)\n\n    # Copy the pixels from the original image to the new image, but only for the areas where the mask value is not zero\n    extracted_image[np.where(mask_value != False)] = original_image[np.where(mask_value != False)]\n\n    # Save the extracted portion of the image as a new image file\n#     cv2.imwrite(\"extracted_image.jpg\", extracted_image)\n    \n    return extracted_image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(IMAGE_DATA):\n    \n    IMAGE_PATH = IMAGE_DATA['IMAGE_PATH']\n    IMAGE_BBOX = IMAGE_DATA['IMAGE_BBOX']\n    image_width = IMAGE_DATA['WIDTH']\n    image_height = IMAGE_DATA['HEIGHT']\n    mask_index = IMAGE_DATA['MASK_INDEX']\n    \n    mask_predictor = load_SAM_predictor()\n    box = get_bbox(IMAGE_BBOX[0], IMAGE_BBOX[1],\n                   IMAGE_BBOX[2], IMAGE_BBOX[3], image_width, image_height)\n    \n    masks, scores, logits = predict_mask(IMAGE_PATH, mask_predictor, box)\n    segmented_image = visualize_predicted_masks(masks, box, IMAGE_PATH)\n    \n    mask_value = masks[mask_index]\n    \n    tattoo = extract_tattoo(IMAGE_PATH, segmented_image, mask_value)\n    \n    tattoo = cv2.cvtColor(tattoo, cv2.COLOR_BGR2RGB)\n    plt.imshow(tattoo)\n    tattoo.shape\n    return tattoo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport supervision as sv\nimport numpy as np\n\n# IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)\n# IMAGE_PATH = '/kaggle/input/small-tattoo-dataset/WhatsApp Image 2022-11-20 at 19.08.20 (4).jpeg'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# IMAGE_PATH = '/kaggle/input/small-tattoo-dataset/IMG_1004.jpg'\n# IMAGE_BBOX = [0.507212, 0.600962, 0.144231, 0.149038]\n\n# WIDTH = 416\n# HEIGHT = 416\n# MASK_INDEX = 0\n\n# IMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n#               'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n#               'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\n# main(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name):\n\n#     IMAGE_PATH = '/kaggle/input/small-tattoo-dataset/IMG_1004.jpg'\n#     IMAGE_BBOX = [0.507212, 0.600962, 0.144231, 0.149038]\n\n    WIDTH = 416\n    HEIGHT = 416\n    MASK_INDEX = 0\n\n    IMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n                  'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n                  'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\n    tattoo = main(IMAGE_DATA)\n    cv2.imwrite(f\"/kaggle/working/tattoo_images/{image_name}\", tattoo)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_andrea10.jpg\"\n\nimage_name = \"resized_andrea10.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.481971 0.479567 0.420673 0.329327\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir /kaggle/working/tattoo_images\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_andrea10.jpg\"\n\nimage_name = \"resized_andrea10.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.481971 0.479567 0.420673 0.329327\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_1008.jpg\"\n\nimage_name = \"resized_IMG_1008.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.4375 0.415865 0.389423 0.370192\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_1012.jpg\"\n\nimage_name = \"resized_IMG_1012.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.47476 0.519231 0.598558 0.625\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_2486.jpg\"\n\nimage_name = \"resized_IMG_2486.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.575721 0.514423 0.848558 0.283654\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_2487.jpg\"\n\nimage_name = \"resized_IMG_2487.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.501202 0.448317 0.151442 0.266827\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_2495.jpg\"\n\nimage_name = \"resized_IMG_2495.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.501202 0.61899 0.632212 0.603365\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_2497.jpg\"\n\nimage_name = \"resized_IMG_2497.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.503606 0.501202 0.757212 0.930288\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_2496.jpg\"\n\nimage_name = \"resized_IMG_2496.jpg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.5 0.584135 0.730769 0.740385\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-21 at 12.08.46 (1).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-21 at 12.08.46 (1).jpeg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.501202 0.481971 0.757212 0.310096\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.41.07 (6).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.41.07 (6).jpeg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.450721 0.408654 0.78125 0.778846\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.08.19.jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.08.19.jpeg\"\n\nMASK_INDEX = 2\n\nIMAGE_BBOX = \"0.503606 0.402644 0.319712 0.175481\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.41.05 (2).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.41.05 (2).jpeg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.47476 0.590144 0.771635 0.709135\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.08.20 (7).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.08.20 (7).jpeg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.78726 0.384615 0.324519 0.557692\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.08.21 (2).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.08.21 (2).jpeg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.504808 0.479567 0.394231 0.266827\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_WhatsApp Image 2022-11-20 at 19.08.20 (5).jpeg\"\n\nimage_name = \"resized_WhatsApp Image 2022-11-20 at 19.08.20 (5).jpeg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.359375 0.492788 0.473558 0.259615\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_siuky5.jpg\"\n\nimage_name = \"resized_siuky5.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.484375 0.5 0.536058 0.572115\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_4482.jpg\"\n\nimage_name = \"resized_IMG_4482.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.513221 0.449519 0.71875 0.894231\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"/kaggle/input/resized-tattoo-images/resized_IMG_4461.jpg\"\n\nimage_name = \"resized_IMG_4461.jpg\"\n\nMASK_INDEX = 0\n\nIMAGE_BBOX = \"0.491587 0.486779 0.834135 0.685096\"\n\nIMAGE_BBOX = [float(i) for i in IMAGE_BBOX.split()]\n\n\nget_tattoo(IMAGE_PATH, IMAGE_BBOX, MASK_INDEX, image_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r \"/kaggle/working/tattoo_images\" \"/kaggle/working/new\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working/tattoo_images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = '/kaggle/input/small-tattoo-dataset/IMG_2701.jpg'\nIMAGE_BBOX = [0.483173, 0.350962, 0.947115, 0.230769]\n\nWIDTH = 416\nHEIGHT = 416\nMASK_INDEX = 2\n\nIMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n              'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n              'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\nmain(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_PATH = '/kaggle/input/small-tattoo-dataset/IMG_4474.jpg'\nIMAGE_BBOX = [0.373798, 0.802885, 0.536058, 0.298077]\n\nWIDTH = 416\nHEIGHT = 416\nMASK_INDEX = 0\n\nIMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n              'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n              'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\nmain(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_PATH = '/kaggle/input/small-tattoo-dataset/toan-nguyen-gSO-66i1ZnI-unsplash.JPG'\nIMAGE_BBOX = [0.486779, 0.620192, 0.199519, 0.278846]\n\nWIDTH = 416\nHEIGHT = 416\nMASK_INDEX = 2\n\nIMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n              'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n              'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\nmain(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nIMAGE_PATH = '/kaggle/input/small-tattoo-dataset/WhatsApp Image 2022-11-20 at 19.08.21 (1).jpeg'\nIMAGE_BBOX = [0.519231, 0.509615, 0.543269, 0.298077]\n\nWIDTH = 416\nHEIGHT = 416\nMASK_INDEX = 2\n\nIMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n              'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n              'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\nmain(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nIMAGE_PATH = '/kaggle/input/small-tattoo-dataset/WhatsApp Image 2022-11-20 at 19.08.21 (1).jpeg'\nIMAGE_BBOX = [0.441106 0.507212 0.194712, 0.235577]\n\nWIDTH = 416\nHEIGHT = 416\nMASK_INDEX = 2\n\nIMAGE_DATA = {'IMAGE_PATH': IMAGE_PATH,\n              'IMAGE_BBOX': IMAGE_BBOX, 'WIDTH': WIDTH,\n              'HEIGHT': HEIGHT, 'MASK_INDEX': MASK_INDEX}\n\nmain(IMAGE_DATA)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = 0.512019\n# b = 0.564904\n# aa = 0.322115\n# bb = 0.533654\n\n\n# a, b, aa, bb = 0.481971, 0.433894, 0.353365, 0.257212\n\n# a, b, aa, bb = 0.5125, 0.603437, 0.158333, 0.143125\n\n\n# 1\na, b, aa, bb, = 0.507212, 0.600962, 0.144231, 0.149038\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BGR","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seg","metadata":{}},{"cell_type":"markdown","source":"## Segment Anything in Roboflow Universe Dataset","metadata":{"id":"S14Wh-hhr3wP"}},{"cell_type":"markdown","source":"### Utils Supporting Dataset Processing\n\nA couple of helper functions that, unfortunately, we have to write ourselves to facilitate the processing of COCO annotations.","metadata":{"id":"Ff80d5krPlkO"}},{"cell_type":"code","source":"import numpy as np\nfrom dataclasses import dataclass\nfrom typing import List, Tuple, Union, Optional\nfrom dataclasses_json import dataclass_json\nfrom supervision import Detections\n\n\n@dataclass_json\n@dataclass\nclass COCOCategory:\n    id: int\n    name: str\n    supercategory: str\n\n\n@dataclass_json\n@dataclass\nclass COCOImage:\n    id: int\n    width: int\n    height: int\n    file_name: str\n    license: int\n    date_captured: str\n    coco_url: Optional[str] = None\n    flickr_url: Optional[str] = None\n\n\n@dataclass_json\n@dataclass\nclass COCOAnnotation:\n    id: int\n    image_id: int\n    category_id: int\n    segmentation: List[List[float]]\n    area: float\n    bbox: Tuple[float, float, float, float]\n    iscrowd: int\n\n\n@dataclass_json\n@dataclass\nclass COCOLicense:\n    id: int\n    name: str\n    url: str\n\n\n@dataclass_json\n@dataclass\nclass COCOJson:\n    images: List[COCOImage]\n    annotations: List[COCOAnnotation]\n    categories: List[COCOCategory]\n    licenses: List[COCOLicense]\n\n\ndef load_coco_json(json_file: str) -> COCOJson:\n    import json\n\n    with open(json_file, \"r\") as f:\n        json_data = json.load(f)\n\n    return COCOJson.from_dict(json_data)\n\n\nclass COCOJsonUtility:\n    @staticmethod\n    def get_annotations_by_image_id(coco_data: COCOJson, image_id: int) -> List[COCOAnnotation]:\n        return [annotation for annotation in coco_data.annotations if annotation.image_id == image_id]\n\n    @staticmethod\n    def get_annotations_by_image_path(coco_data: COCOJson, image_path: str) -> Optional[List[COCOAnnotation]]:\n        image = COCOJsonUtility.get_image_by_path(coco_data, image_path)\n        if image:\n            return COCOJsonUtility.get_annotations_by_image_id(coco_data, image.id)\n        else:\n            return None\n\n    @staticmethod\n    def get_image_by_path(coco_data: COCOJson, image_path: str) -> Optional[COCOImage]:\n        for image in coco_data.images:\n            if image.file_name == image_path:\n                return image\n        return None\n\n    @staticmethod\n    def annotations2detections(annotations: List[COCOAnnotation]) -> Detections:\n        class_id, xyxy = [], []\n\n        for annotation in annotations:\n            x_min, y_min, width, height = annotation.bbox\n            class_id.append(annotation.category_id)\n            xyxy.append([\n                x_min,\n                y_min,\n                x_min + width,\n                y_min + height\n            ])\n\n        return Detections(\n            xyxy=np.array(xyxy, dtype=int),\n            class_id=np.array(class_id, dtype=int)\n        )","metadata":{"id":"dZSU9BpHr2gc","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download Dataset from Roboflow","metadata":{"id":"W-jQ5c4TQAic"}},{"cell_type":"code","source":"%cd {HOME}\n\nimport roboflow\nfrom roboflow import Roboflow\n\n# roboflow.login()\n\n# rf = Roboflow()\n\n# project = rf.workspace(\"hashira-fhxpj\").project(\"mri-brain-tumor\")\n# dataset = project.version(1).download(\"coco\")\n\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"1Pt0GpqOFPYhcRmLYYm3\")\nproject = rf.workspace(\"octa-cube\").project(\"tatto-detection-pjkn9\")\ndataset = project.version(1).download(\"yolov5\")","metadata":{"id":"DxH9V2nHQC4M","outputId":"db636b05-8727-47e1-c0d9-6a95270995e7","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working/Tatto-detection-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.location","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nDATA_SET_SUBDIRECTORY = \"test\"\nANNOTATIONS_FILE_NAME = \"README.roboflow.txt\"\nIMAGES_DIRECTORY_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY)\nANNOTATIONS_FILE_PATH = os.path.join(dataset.location, ANNOTATIONS_FILE_NAME)","metadata":{"id":"N-Xi4Dx0QuRL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coco_data = load_coco_json(json_file=ANNOTATIONS_FILE_PATH)\n\nCLASSES = [\n    category.name\n    for category\n    in coco_data.categories\n    if category.supercategory != 'none'\n]\n\nIMAGES = [\n    image.file_name\n    for image\n    in coco_data.images\n]","metadata":{"id":"a8b3oKP0QyiB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES","metadata":{"id":"QFQwR9-aQ0kx","outputId":"c0e0e9e6-8e63-4b02-d9d1-a11b6bae689d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Single Image Bounding Box to Mask","metadata":{"id":"s3WqT5qTQ6tI"}},{"cell_type":"code","source":"# set random seed to allow easy reproduction of the experiment\n\nimport random\nrandom.seed(10)","metadata":{"id":"MuUKYCLnRAaN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXAMPLE_IMAGE_NAME = random.choice(IMAGES)\nEXAMPLE_IMAGE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, EXAMPLE_IMAGE_NAME)\n\n# load dataset annotations\nannotations = COCOJsonUtility.get_annotations_by_image_path(coco_data=coco_data, image_path=EXAMPLE_IMAGE_NAME)\nground_truth = COCOJsonUtility.annotations2detections(annotations=annotations)\n\n# small hack - coco numerate classes from 1, model from 0 + we drop first redundant class from coco json\nground_truth.class_id = ground_truth.class_id - 1\n\n# load image\nimage_bgr = cv2.imread(EXAMPLE_IMAGE_PATH)\nimage_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n\n# initiate annotator\nbox_annotator = sv.BoxAnnotator(color=sv.Color.red())\nmask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n\n# annotate ground truth\nannotated_frame_ground_truth = box_annotator.annotate(scene=image_bgr.copy(), detections=ground_truth, skip_label=True)\n\n# run SAM inference\nmask_predictor.set_image(image_rgb)\n\nmasks, scores, logits = mask_predictor.predict(\n    box=ground_truth.xyxy[0],\n    multimask_output=True\n)\n\ndetections = sv.Detections(\n    xyxy=sv.mask_to_xyxy(masks=masks),\n    mask=masks\n)\ndetections = detections[detections.area == np.max(detections.area)]\n\nannotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n\nsv.plot_images_grid(\n    images=[annotated_frame_ground_truth, annotated_image],\n    grid_size=(1, 2),\n    titles=['source image', 'segmented image']\n)","metadata":{"id":"RHw4yH8XRCo9","outputId":"1fce1a3b-506e-4a18-d3a8-84f297a37e2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🏆 Congratulations\n\n### Learning Resources\n\nRoboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n\n- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n\n### Convert data formats\n\nRoboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n\n### Connect computer vision to your project logic\n\n[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections.","metadata":{"id":"gP9gEw9Tp8GJ"}}]}